#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿå·¥å…·æ¨¡å— - ä¸ºæ•…éšœè¯Šæ–­æ™ºèƒ½ä½“æä¾›æ¨¡æ‹Ÿæ•°æ®
"""
from crewai.tools import tool
from datetime import datetime
from typing import List, Dict, Any, Optional, Union,Tuple

# æ’é™¤test_dataä»æ–‡ä»¶å±‚é¢å¯¼å…¥å¤±è´¥ï¼šä¿®æ”¹ä¸ºç»å¯¹å¯¼å…¥ï¼Œå»æ‰ç›¸å¯¹å¯¼å…¥çš„ç‚¹
try:
    # å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥
    from test_data import (
        generate_servers,
        generate_nginx_logs_for_server,
        generate_metrics_for_server
    )
except ImportError:
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä»çˆ¶ç›®å½•å¯¼å…¥
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from test_data import (
        generate_servers,
        generate_nginx_logs_for_server,
        generate_metrics_for_server
    )

# å°è¯•å¯¼å…¥ MySQL mock æ•°æ®ç”Ÿæˆå™¨
try:
    from mysql_test_data import generate_mysql_logs_for_server
except ImportError:
    import sys, os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from mysql_test_data import generate_mysql_logs_for_server

# å°è¯•å¯¼å…¥ Redis mock æ•°æ®ç”Ÿæˆå™¨
try:
    from redis_test_data import generate_redis_logs_for_server
except ImportError:
    import sys, os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from redis_test_data import generate_redis_logs_for_server

# ==================== ç®€åŒ–çš„å·¥å…·ç‰ˆæœ¬ï¼ˆè§£å†³CrewAIéªŒè¯é—®é¢˜ï¼‰====================

@tool("è·å–NginxæœåŠ¡å™¨åˆ—è¡¨")
def get_nginx_servers() -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰NginxæœåŠ¡å™¨çš„IPåœ°å€å’ŒåŸºæœ¬ä¿¡æ¯ã€‚"""
    print(f"[å·¥å…·è°ƒç”¨] get_nginx_servers() - è·å–æœåŠ¡å™¨åˆ—è¡¨")
    servers = generate_servers()
    print(f"  æ‰¾åˆ° {len(servers)} å°æœåŠ¡å™¨:")
    for server in servers:
        print(f"  - {server['ip']} ({server['role']}, åŒºåŸŸ: {server['region']})")
    return servers


@tool("è·å–æœåŠ¡å™¨æ—¥å¿—")
def get_server_logs_simple(
        server_ip: str,
        api_endpoint: str = None,
        keywords: Union[str, List[str]] = None
) -> List[Dict[str, Any]]:
    """
    è·å–æœåŠ¡å™¨æ—¥å¿—ï¼ˆNginxï¼‰ï¼Œå¹¶è¾“å‡ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1ï¼š
    æ ¹æ®ã€å…³é”®è¯æˆ–è€…æ—¶é—´æˆ³ã€‘ã€åˆ†æ‰¹ã€‘æœç´¢å‡ºæ¥
    {
        "source": "nginx",
        "server_ip": "...",
        "timestamp": "...",
        "severity": "...",
        "operation": "GET /api/v2/data.json",
        "status": "502",
        "latency_ms": 200.5,
        "raw": "åŸå§‹æ—¥å¿—"
    }
    """
    print(f"[å·¥å…·è°ƒç”¨] get_server_logs_simple('{server_ip}', api_endpoint={api_endpoint}, keywords={keywords})")

    # ç”Ÿæˆæ—¥å¿—
    logs = generate_nginx_logs_for_server(server_ip, 60)

    # ------------------------------
    # â‘  æŒ‰ æ¥å£è·¯å¾„ è¿‡æ»¤
    # ------------------------------
    if api_endpoint:
        logs = [log for log in logs if api_endpoint in log]

    # ------------------------------
    # â‘¡ æŒ‰å…³é”®è¯è¿‡æ»¤ï¼šä¸åŒºåˆ†å¤§å°å†™
    # ------------------------------
    if keywords:
        if isinstance(keywords, str):
            keywords = [keywords]

        logs = [
            log for log in logs
            if any(k.lower() in log.lower() for k in keywords)
        ]

    print(f"[å·¥å…·è°ƒç”¨] æ‰¾åˆ° {len(logs)} æ¡ç›¸å…³æ—¥å¿—")

    # ------------------------------
    # â‘¢ è§£æ Nginx æ—¥å¿— â†’ ç»Ÿä¸€ç»“æ„ UnifiedLogV1
    # ------------------------------
    structured_logs = []

    for log in logs[:10]:  # ä»ç„¶åªå¤„ç†å‰10æ¡ï¼Œé¿å…LLMè´Ÿè½½è¿‡å¤§
        try:
            import re

            # è·¯å¾„
            path_match = re.search(r'"(GET|POST)\s+([^\s?]+)', log)
            method = path_match.group(1) if path_match else "UNKNOWN"
            path = path_match.group(2) if path_match else "unknown"

            # çŠ¶æ€ç 
            status_match = re.search(r'"\s+(\d{3})\s+', log)
            status_code = status_match.group(1) if status_match else "000"

            # å“åº”æ—¶é—´
            rt_match = re.search(r'([\d.]+)$', log)
            response_time = float(rt_match.group(1)) if rt_match else 0.0
            latency_ms = response_time * 1000

            # IP
            ip_match = re.match(r'(\S+)', log)
            client_ip = ip_match.group(1) if ip_match else "0.0.0.0"

            # æ—¶é—´æˆ³
            time_match = re.search(r'\[(.*?)\]', log)
            timestamp = time_match.group(1) if time_match else ""

            # ------------------------------
            # ç»Ÿä¸€ç»“æ„ UnifiedLogV1
            # ------------------------------
            structured_logs.append({
                "source": "nginx",
                "server_ip": server_ip,
                "timestamp": timestamp,
                "severity": "ERROR" if int(status_code) >= 500 else "INFO",
                "operation": f"{method} {path}",
                "status": status_code,
                "latency_ms": latency_ms,
                "raw": log
            })

        except Exception as e:
            print(f"[è­¦å‘Š] è§£ææ—¥å¿—å¤±è´¥: {e}")
            continue

    return structured_logs


@tool("è·å–MySQLæ—¥å¿—")
def get_mysql_logs_simple(
        server_ip: str,
        start_time: str = "",
        end_time: str = "",
        keywords: str = "",
        min_duration_s: float = 0.0,
        limit: int = 1000
) -> Tuple[List[Dict[str, Any]], Optional[str]]:
    """
    è·å– MySQL æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿï¼‰ï¼Œå¹¶è§£æä¸ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1 æ ¼å¼ã€‚

    å‚æ•°:
        server_ip: æœåŠ¡å™¨IPåœ°å€ (å¿…é¡»)
        start_time: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼: "YYYY-MM-DD HH:MM:SS" (å¯é€‰ï¼Œé»˜è®¤ä¸ºç©º)
        end_time: ç»“æŸæ—¶é—´ï¼Œæ ¼å¼: "YYYY-MM-DD HH:MM:SS" (å¯é€‰ï¼Œé»˜è®¤ä¸ºç©º)
        keywords: å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚: "timeout,error" (å¯é€‰ï¼Œé»˜è®¤ä¸ºç©º)
        min_duration_s: æœ€å°è€—æ—¶(ç§’)ï¼Œç”¨äºç­›é€‰æ…¢æŸ¥è¯¢ (å¯é€‰ï¼Œé»˜è®¤ä¸º0.0)
        limit: è¿”å›æ—¥å¿—æ•°é‡é™åˆ¶ (å¯é€‰ï¼Œé»˜è®¤ä¸º1000)
    """
    print(f"[å·¥å…·è°ƒç”¨] get_mysql_logs_simple - server_ip: {server_ip}")

    # å¤„ç† keywords å‚æ•°
    keywords_list = []
    if keywords:
        # å¦‚æœ keywords æ˜¯åˆ—è¡¨ï¼ˆæ¥è‡ª Agent çš„é”™è¯¯è°ƒç”¨ï¼‰ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(keywords, list):
            keywords = ",".join(str(k) for k in keywords)
            print(f"[è°ƒè¯•] è‡ªåŠ¨è½¬æ¢ keywords ä¸ºå­—ç¬¦ä¸²: {keywords}")
        keywords_list = [k.strip() for k in keywords.split(",") if k.strip()]

    # ç¡®ä¿å…¶ä»–å‚æ•°æœ‰åˆç†çš„é»˜è®¤å€¼
    start_time = start_time if start_time else None
    end_time = end_time if end_time else None
    min_duration_s_val = float(min_duration_s) if min_duration_s else 0.0

    print(
        f"  å‚æ•°: start_time={start_time}, end_time={end_time}, keywords={keywords_list}, min_duration_s={min_duration_s_val}, limit={limit}")

    # åŸæœ‰çš„æ—¥å¿—ç”Ÿæˆå’Œè§£æé€»è¾‘...
    # è¿™é‡Œä¿æŒä¸å˜
    # ...
    # ä¿®å¤è¿™é‡Œï¼šå®‰å…¨åœ°å¤„ç† min_duration_s æ¯”è¾ƒ
    if min_duration_s is not None:
        min_duration_s_val = float(min_duration_s) if min_duration_s else 0.0
    else:
        min_duration_s_val = None

    # åŸæœ‰çš„ç”Ÿæˆå’Œè§£æé€»è¾‘ä¿æŒä¸å˜...
    # 1. ç”Ÿæˆæ—¥å¿—ï¼ˆåŸå§‹å­—ç¬¦ä¸²ï¼‰
    raw_logs = generate_mysql_logs_for_server(server_ip, 60)

    # è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¶é—´å­—ç¬¦ä¸²ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    def parse_time_string(time_str: str) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        if not time_str:
            return None

        try:
            # å°è¯•è§£æ ISO æ ¼å¼ (2024-12-01T00:00:00)
            if 'T' in time_str:
                time_str = time_str.replace('T', ' ')
                # å¦‚æœåŒ…å«æ¯«ç§’ï¼Œç§»é™¤æ¯«ç§’éƒ¨åˆ†
                if '.' in time_str:
                    time_str = time_str.split('.')[0]
        except Exception:
            pass

        try:
            return datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            try:
                return datetime.fromisoformat(time_str)
            except Exception:
                print(f"[è­¦å‘Š] æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
                return None

    # è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¥å¿—æ—¶é—´æˆ³
    def parse_ts(log: str) -> Optional[datetime]:
        try:
            # å°è¯•è§£ææ—¥å¿—ä¸­çš„æ—¶é—´æˆ³
            ts_str = log[:19]  # å‡è®¾æ ¼å¼ä¸º "YYYY-MM-DD HH:MM:SS"
            return datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S")
        except Exception:
            return None

    # ------------------------------
    # å…³é”®è¯è¿‡æ»¤
    # ------------------------------
    if keywords_list:
        raw_logs = [log for log in raw_logs if any(k.lower() in log.lower() for k in keywords_list)]

    # ------------------------------
    # æœ€å°è€—æ—¶è¿‡æ»¤ï¼ˆç­›é€‰æ…¢ SQLï¼‰
    # ä¿®å¤è¿™é‡Œï¼šç¡®ä¿æ¯”è¾ƒå®‰å…¨
    # ------------------------------
    if min_duration_s_val and min_duration_s_val > 0:
        filtered = []
        for log in raw_logs:
            import re
            duration_match = re.search(r'duration=([\d.]+)s', log)
            if duration_match:
                duration = float(duration_match.group(1))
                if duration >= min_duration_s_val:
                    filtered.append(log)
        raw_logs = filtered

    # ------------------------------
    # æ—¶é—´çª—è¿‡æ»¤ï¼ˆé™æµï¼‰
    # ------------------------------
    if start_time:
        start_dt = parse_time_string(start_time)
        if start_dt:
            raw_logs = [log for log in raw_logs if parse_ts(log) and parse_ts(log) >= start_dt]

    if end_time:
        end_dt = parse_time_string(end_time)
        if end_dt:
            raw_logs = [log for log in raw_logs if parse_ts(log) and parse_ts(log) <= end_dt]

    # æ’åºï¼Œå°†æ‰€æœ‰æ—¥å¿—æŒ‰ç…§æ—¶é—´æˆ³å‡åºæ’åº
    raw_logs.sort(key=lambda x: parse_ts(x) or datetime.min)
    print(f"[å·¥å…·è°ƒç”¨] æ‰¾åˆ° {len(raw_logs)} æ¡ MySQL æ—¥å¿—")

    # ------------------------------
    # è§£æ â†’ ç»Ÿä¸€ç»“æ„ UnifiedLogV1
    #       â†’ å¹¶åªç­›é€‰limitæ¡æ—¥å¿—
    # ------------------------------
    # æ‰¹æ¬¡åˆ‡ç‰‡
    batch_logs = raw_logs[:limit]
    structured_logs = []
    next_start_time = None

    for log in batch_logs:
        try:
            import re
            # æ—¶é—´æˆ³
            ts = log[:19]
            # ä¸¥é‡çº§åˆ«
            sev_match = re.search(r"\[(INFO|WARN|ERROR)\]", log)
            severity = sev_match.group(1) if sev_match else "INFO"

            # SQL
            sql_match = re.search(r'sql="([^"]+)"', log)
            sql = sql_match.group(1) if sql_match else "UNKNOWN SQL"

            # è€—æ—¶
            dur_match = re.search(r'duration=([\d.]+)s', log)
            latency_ms = float(dur_match.group(1)) * 1000 if dur_match else 0.0

            status = "ERROR" if severity == "ERROR" else "OK"

            structured_logs.append({
                "source": "mysql",
                "server_ip": server_ip,
                "timestamp": ts,
                "severity": severity,
                "operation": sql,
                "status": status,
                "latency_ms": latency_ms,
                "raw": log
            })

            next_start_time = ts

        except Exception as e:
            print(f"[è­¦å‘Š] è§£æ MySQL æ—¥å¿—å¤±è´¥: {e}")
            continue

    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
    if len(batch_logs) < limit:
        next_start_time = None

    return structured_logs, next_start_time

@tool("MYSQLè¿è¡Œæ—¶è¯Šæ–­")
def mysql_runtime_diagnosis(
        server_ip: str,
        action: str,
) -> Dict[str, Any]:
    """
        MySQL è¿è¡Œæ—¶è¯Šæ–­å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰

        ç”¨äºè·å–æ—¥å¿—ä¸­æ— æ³•ç›´æ¥ä½“ç°çš„æ•°æ®åº“â€œç°åœºçŠ¶æ€â€ï¼Œä¾‹å¦‚ï¼š
        - å½“å‰æ­£åœ¨æ‰§è¡Œçš„ SQLï¼ˆprocesslistï¼‰
        - æœ€è¿‘å‘ç”Ÿçš„æ­»é”ä¿¡æ¯ï¼ˆInnoDB statusï¼‰
        - æ•°æ®åº“å…³é”®é…ç½®å‚æ•°

        å‚æ•°ï¼š
        - server_ip: æ•°æ®åº“æ‰€åœ¨æœåŠ¡å™¨ IP
        - action: è¯Šæ–­åŠ¨ä½œç±»å‹ï¼Œå¯é€‰å€¼ï¼š
            * processlist
            * innodb_status
            * variables
            * connections
        """
    print(f"[å·¥å…·è°ƒç”¨] mysql_runtime_diagnosis(server_ip={server_ip}, action={action})")

    if action == "processlist":
        #æ¨¡æ‹ŸSHOW PROCESSLIST
        return {
            "type" : "processlist",
            "processes": [
                {
                    "id": 1234,
                    "user": "app_user",
                    "db": "order_db",
                    "time_sec": 85,
                    "state": "Waiting for lock",
                    "sql": "UPDATE orders SET status='PAID' WHERE id=10001"
                },
                {
                    "id": 1235,
                    "user": "report_user",
                    "db": "order_db",
                    "time_sec": 2,
                    "state": "Sending data",
                    "sql": "SELECT * FROM orders WHERE created_at > NOW() - INTERVAL 1 DAY"
                }
            ]
        }

    elif action == "innodb_status":
        #æ¨¡æ‹ŸSHOW ENGINE INNODB STATUS
        return {
            "type": "innodb_status",
            "latest_deadlock": {
                "transaction_1": "UPDATE orders SET status='PAID' WHERE id=10001",
                "transaction_2": "UPDATE orders SET status='CANCEL' WHERE id=10001",
                "locked_table": "orders",
                "locked_index": "PRIMARY",
                "note": "ä¸¤ä¸ªäº‹åŠ¡äº’ç›¸ç­‰å¾…è¡Œé”ï¼Œäº§ç”Ÿæ­»é”"
            }
        }
    elif action == "variables":
        # æ¨¡æ‹Ÿ SHOW VARIABLES
        return {
            "type": "variables",
            "slow_query_log": "ON",
            "slow_query_log_file": "/var/log/mysql/slow.log",
            "long_query_time": 2,
            "max_connections": 500
        }

    elif action == "connections":
        # æ¨¡æ‹Ÿ SHOW STATUS LIKE 'Threads_%'
        return {
            "type": "connections",
            "threads_connected": 480,
            "threads_running": 120,
            "max_connections": 500,
            "warning": "è¿æ¥æ•°æ¥è¿‘ä¸Šé™"
        }

    else:
        return {
            "error": f"ä¸æ”¯æŒçš„è¯Šæ–­åŠ¨ä½œ: {action}"
        }

@tool("è·å–Redisæ—¥å¿—")
def get_redis_logs_simple(
    server_ip: str,
    keywords: Optional[Union[str, List[str]]] = None,
    min_duration: Optional[float] = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """
    è·å– Redis æ—¥å¿—å¹¶è§£ææˆ UnifiedLogV1 æ ¼å¼
    """

    print(f"[å·¥å…·è°ƒç”¨] get_redis_logs_simple('{server_ip}', keywords={keywords}, min_duration_s={min_duration})")

    logs = generate_redis_logs_for_server(server_ip, 60)

    # å…³é”®è¯è¿‡æ»¤
    if keywords:
        if isinstance(keywords, str):
            keywords = [keywords]
        logs = [log for log in logs if any(k.lower() in log.lower() for k in keywords)]

    # æœ€å°è€—æ—¶è¿‡æ»¤
    if min_duration:
        filtered = []
        for log in logs:
            import re
            dur_match = re.search(r'duration=(\d+)ms', log)
            if dur_match:
                dur_ms = int(dur_match.group(1))
                if dur_ms >= min_duration * 1000:
                    filtered.append(log)
        logs = filtered

    # ç»Ÿä¸€ç»“æ„åŒ–
    structured = []
    import re

    for log in logs[:15]:
        try:
            ts = re.match(r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})", log).group(1)
            severity = re.search(r"\[(INFO|WARN|ERROR|SLOWLOG)\]", log).group(1)

            cmd_match = re.search(r'command="([^"]+)"', log)
            command = cmd_match.group(1) if cmd_match else "UNKNOWN"

            dur_match = re.search(r'duration=(\d+)ms', log)
            latency_ms = int(dur_match.group(1)) if dur_match else 0

            status = "ERROR" if "ERROR" in severity else "OK"

            structured.append({
                "source": "redis",
                "server_ip": server_ip,
                "timestamp": ts,
                "severity": severity,
                "operation": command,
                "status": status,
                "latency_ms": latency_ms,
                "raw": log
            })

        except Exception as e:
            print(f"[è­¦å‘Š] Redis æ—¥å¿—è§£æå¤±è´¥: {e}")
            continue

    return structured

@tool("è·å–æœåŠ¡å™¨æŒ‡æ ‡")
def get_server_metrics_simple(
        server_ip: str,
        metric_name: str = None
) -> Dict[str, Any]:
    """
    ç®€åŒ–çš„æŒ‡æ ‡è·å–å·¥å…·ï¼Œé¿å…å¤æ‚çš„å‚æ•°éªŒè¯é—®é¢˜ã€‚

    å‚æ•°:
        server_ip (str): æœåŠ¡å™¨IPåœ°å€
        metric_name (str): æŒ‡æ ‡åç§°ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        æŒ‡æ ‡æ•°æ®
    """
    print(f"[å·¥å…·è°ƒç”¨] get_server_metrics_simple('{server_ip}', metric_name={metric_name})")

    # ç”Ÿæˆæ¨¡æ‹ŸæŒ‡æ ‡
    all_metrics = generate_metrics_for_server(server_ip, 60)

    # è¿‡æ»¤æŒ‡å®šçš„æŒ‡æ ‡
    if metric_name:
        metric_mapping = {
            "cpu": "cpu_percent",
            "cpu_usage_total": "cpu_percent",
            "å†…å­˜": "memory_percent",
            "memory": "memory_percent",
            "ç£ç›˜": "disk_percent",
            "disk": "disk_percent",
            "æˆåŠŸç‡": "success_rate",
            "é”™è¯¯ç‡": "success_rate",
            "å»¶è¿Ÿ": "avg_latency_ms",
            "å“åº”æ—¶é—´": "avg_latency_ms"
        }

        actual_key = metric_mapping.get(metric_name.lower(), metric_name)
        if actual_key in all_metrics:
            return {actual_key: all_metrics[actual_key]}
        else:
            return {"error": f"æœªæ‰¾åˆ°æŒ‡æ ‡: {metric_name}"}
    else:
        # è¿”å›æ‰€æœ‰æŒ‡æ ‡
        return all_metrics


# ==================== åŸæ¥çš„å®Œæ•´ç‰ˆæœ¬ï¼ˆä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼‰ ====================

def get_server_logs_full(
        server_ip: str,
        keywords: Optional[Union[str, List[str]]] = None,
        start_time: Optional[str] = None,
        end_time: Optional[str] = None,
        time_range_minutes: int = 60,
        max_logs: int = 10000,
        error_codes: Optional[List[str]] = None,
        min_response_time: Optional[float] = None
) -> List[Dict[str, Any]]:
    """
    å®Œæ•´çš„æ—¥å¿—è·å–å‡½æ•°ï¼ˆä½†ä¸ç”¨ä½œCrewAIå·¥å…·ï¼‰
    """
    # ... å®Œæ•´å®ç°ï¼ˆä½†ä¸ç”¨@toolè£…é¥°å™¨ï¼‰...
    pass


def get_server_metrics_full(
        server_ip: str,
        time_range_minutes: int = 60,
        metric_name: Optional[Union[str, List[str]]] = None
) -> Dict[str, Any]:
    """
    å®Œæ•´çš„æŒ‡æ ‡è·å–å‡½æ•°ï¼ˆä½†ä¸ç”¨ä½œCrewAIå·¥å…·ï¼‰
    """
    # ... å®Œæ•´å®ç°ï¼ˆä½†ä¸ç”¨@toolè£…é¥°å™¨ï¼‰...
    pass


# åœ¨ mock_tools.py æ–‡ä»¶çš„æœ€åæ·»åŠ ï¼š

def test_tools_locally():
    """æœ¬åœ°æµ‹è¯•å·¥å…·å‡½æ•°"""
    print("ğŸ”§ æœ¬åœ°æµ‹è¯•å·¥å…·å‡½æ•°")

    # æµ‹è¯•æœåŠ¡å™¨åˆ—è¡¨
    servers = get_nginx_servers.function()
    print(f"è·å–åˆ° {len(servers)} å°æœåŠ¡å™¨")

    # æµ‹è¯•è·å–ç‰¹å®šæœåŠ¡å™¨çš„æ—¥å¿—
    test_server = "10.0.2.101"
    print(f"\næµ‹è¯•æœåŠ¡å™¨ {test_server} çš„æ—¥å¿—:")
    logs = get_server_logs_simple.function(test_server, api_endpoint="/api/v2/data.json")
    print(f"è·å–åˆ° {len(logs)} æ¡æ—¥å¿—")

    if logs:
        for log in logs[:3]:
            print(f"  - ä¸¥é‡çº§åˆ«: {log['severity']}, æ“ä½œ: {log['operation']}")

    # æµ‹è¯•è·å–æŒ‡æ ‡
    print(f"\næµ‹è¯•æœåŠ¡å™¨ {test_server} çš„æŒ‡æ ‡:")
    metrics = get_server_metrics_simple.function(test_server, metric_name="cpu")
    print(f"CPUä½¿ç”¨ç‡: {metrics.get('cpu_percent', 'N/A')}%")

    print("\nâœ… æœ¬åœ°æµ‹è¯•å®Œæˆ")


def verify_log_format():
    """éªŒè¯æ—¥å¿—æ ¼å¼æ˜¯å¦æ­£ç¡®"""
    print("ğŸ” éªŒè¯æ—¥å¿—æ ¼å¼")
    print("=" * 60)

    from test_data import generate_nginx_logs_for_server

    # ç”Ÿæˆæµ‹è¯•æ—¥å¿—
    test_logs = generate_nginx_logs_for_server("10.0.2.101", 1)  # ç”Ÿæˆå°‘é‡æ—¥å¿—

    if not test_logs:
        print("âŒ æ²¡æœ‰ç”Ÿæˆæ—¥å¿—ï¼")
        return

    print(f"ç”Ÿæˆ {len(test_logs)} æ¡æ—¥å¿—")
    print("\nç¬¬ä¸€æ¡æ—¥å¿—:")
    print(f"  {test_logs[0]}")

    # æ‰‹åŠ¨è§£æ
    log = test_logs[0]
    parts = log.split()

    print(f"\nåˆ†å‰²åå¾—åˆ° {len(parts)} éƒ¨åˆ†:")
    for i, part in enumerate(parts):
        print(f"  [{i}] {part}")

    print("\nå°è¯•è§£æ:")
    try:
        # æ–¹æ³•1ï¼šæŒ‰ç©ºæ ¼åˆ†å‰²
        ip = parts[0]
        timestamp = parts[3] + " " + parts[4]  # [01/Jan/2024:12:00:00 +0000]
        request = parts[5] + " " + parts[6] + " " + parts[7]  # "GET /api/v2/data.json HTTP/1.1"
        status_code = parts[8]
        response_size = parts[9]

        print(f"  IP: {ip}")
        print(f"  æ—¶é—´: {timestamp}")
        print(f"  è¯·æ±‚: {request}")
        print(f"  çŠ¶æ€ç : {status_code}")
        print(f"  å“åº”å¤§å°: {response_size}")

        # å‰©ä¸‹çš„éƒ¨åˆ†
        for i in range(10, len(parts)):
            print(f"  [{i}] {parts[i]}")

    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")


# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
if __name__ == "__main__":
    verify_log_format()