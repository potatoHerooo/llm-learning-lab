
#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿå·¥å…·æ¨¡å— - ä¸ºæ•…éšœè¯Šæ–­æ™ºèƒ½ä½“æä¾›æ¨¡æ‹Ÿæ•°æ®
"""
from datetime import datetime
from typing import List, Dict, Any, Optional, Union, Tuple

# æ’é™¤test_dataä»æ–‡ä»¶å±‚é¢å¯¼å…¥å¤±è´¥ï¼šä¿®æ”¹ä¸ºç»å¯¹å¯¼å…¥ï¼Œå»æ‰ç›¸å¯¹å¯¼å…¥çš„ç‚¹
try:
    # å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥
    from test_data import (
        generate_servers,
        generate_nginx_logs_for_server,
        generate_metrics_for_server
    )
except ImportError:
    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä»çˆ¶ç›®å½•å¯¼å…¥
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from test_data import (
        generate_servers,
        generate_nginx_logs_for_server,
        generate_metrics_for_server
    )

# å°è¯•å¯¼å…¥ MySQL mock æ•°æ®ç”Ÿæˆå™¨
try:
    from mysql_test_data import generate_mysql_logs_for_server
except ImportError:
    import sys, os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from mysql_test_data import generate_mysql_logs_for_server

# å°è¯•å¯¼å…¥ Redis mock æ•°æ®ç”Ÿæˆå™¨
try:
    from redis_test_data import generate_redis_logs_for_server
except ImportError:
    import sys, os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from redis_test_data import generate_redis_logs_for_server

# ==================== åŸå§‹å‡½æ•°ï¼ˆä¸è£…é¥°ï¼‰====================

def get_nginx_servers_raw() -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰NginxæœåŠ¡å™¨çš„IPåœ°å€å’ŒåŸºæœ¬ä¿¡æ¯ã€‚"""
    print(f"[å·¥å…·è°ƒç”¨] get_nginx_servers() - è·å–æœåŠ¡å™¨åˆ—è¡¨")
    servers = generate_servers()
    print(f"  æ‰¾åˆ° {len(servers)} å°æœåŠ¡å™¨:")
    for server in servers:
        print(f"  - {server['ip']} ({server['role']}, åŒºåŸŸ: {server['region']})")
    return servers


def get_server_logs_simple_raw(
        server_ip: str,
        api_endpoint: str = None,
        keywords: Union[str, List[str]] = None
) -> List[Dict[str, Any]]:
    """
    è·å–æœåŠ¡å™¨æ—¥å¿—ï¼ˆNginxï¼‰ï¼Œå¹¶è¾“å‡ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1ï¼š
    æ ¹æ®ã€å…³é”®è¯æˆ–è€…æ—¶é—´æˆ³ã€‘ã€åˆ†æ‰¹ã€‘æœç´¢å‡ºæ¥
    {
        "source": "nginx",
        "server_ip": "...",
        "timestamp": "...",
        "severity": "...",
        "operation": "GET /api/v2/data.json",
        "status": "502",
        "latency_ms": 200.5,
        "raw": "åŸå§‹æ—¥å¿—"
    }
    """
    print(f"[å·¥å…·è°ƒç”¨] get_server_logs_simple('{server_ip}', api_endpoint={api_endpoint}, keywords={keywords})")

    # ç”Ÿæˆæ—¥å¿—
    logs = generate_nginx_logs_for_server(server_ip, 60)

    # æŒ‰ æ¥å£è·¯å¾„ è¿‡æ»¤
    if api_endpoint:
        logs = [log for log in logs if api_endpoint in log]

    # æŒ‰å…³é”®è¯è¿‡æ»¤ï¼šä¸åŒºåˆ†å¤§å°å†™
    if keywords:
        if isinstance(keywords, str):
            keywords = [keywords]

        logs = [
            log for log in logs
            if any(k.lower() in log.lower() for k in keywords)
        ]

    print(f"[å·¥å…·è°ƒç”¨] æ‰¾åˆ° {len(logs)} æ¡ç›¸å…³æ—¥å¿—")

    # è§£æ Nginx æ—¥å¿— â†’ ç»Ÿä¸€ç»“æ„ UnifiedLogV1
    structured_logs = []

    for log in logs[:10]:  # ä»ç„¶åªå¤„ç†å‰10æ¡ï¼Œé¿å…LLMè´Ÿè½½è¿‡å¤§
        try:
            import re

            # è·¯å¾„
            path_match = re.search(r'"(GET|POST)\s+([^\s?]+)', log)
            method = path_match.group(1) if path_match else "UNKNOWN"
            path = path_match.group(2) if path_match else "unknown"

            # çŠ¶æ€ç 
            status_match = re.search(r'"\s+(\d{3})\s+', log)
            status_code = status_match.group(1) if status_match else "000"

            # å“åº”æ—¶é—´
            rt_match = re.search(r'([\d.]+)$', log)
            response_time = float(rt_match.group(1)) if rt_match else 0.0
            latency_ms = response_time * 1000

            # IP
            ip_match = re.match(r'(\S+)', log)
            client_ip = ip_match.group(1) if ip_match else "0.0.0.0"

            # æ—¶é—´æˆ³
            time_match = re.search(r'\[(.*?)\]', log)
            timestamp = time_match.group(1) if time_match else ""

            # ç»Ÿä¸€ç»“æ„ UnifiedLogV1
            structured_logs.append({
                "source": "nginx",
                "server_ip": server_ip,
                "timestamp": timestamp,
                "severity": "ERROR" if int(status_code) >= 500 else "INFO",
                "operation": f"{method} {path}",
                "status": status_code,
                "latency_ms": latency_ms,
                "raw": log
            })

        except Exception as e:
            print(f"[è­¦å‘Š] è§£ææ—¥å¿—å¤±è´¥: {e}")
            continue

    return structured_logs


def get_mysql_logs_simple_raw(
        server_ip: str,
        start_time: str = "",
        end_time: str = "",
        keywords: str = "",
        min_duration_s: float = 0.0,
        limit: int = 1000
) -> Tuple[List[Dict[str, Any]], Optional[str]]:
    """
    è·å– MySQL æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿï¼‰ï¼Œå¹¶è§£æä¸ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1 æ ¼å¼ã€‚
    """
    print(f"[å·¥å…·è°ƒç”¨] get_mysql_logs_simple - server_ip: {server_ip}")

    # å¤„ç† keywords å‚æ•°
    keywords_list = []
    if keywords:
        if isinstance(keywords, list):
            keywords = ",".join(str(k) for k in keywords)
            print(f"[è°ƒè¯•] è‡ªåŠ¨è½¬æ¢ keywords ä¸ºå­—ç¬¦ä¸²: {keywords}")
        keywords_list = [k.strip() for k in keywords.split(",") if k.strip()]

    # ç¡®ä¿å…¶ä»–å‚æ•°æœ‰åˆç†çš„é»˜è®¤å€¼
    start_time = start_time if start_time else None
    end_time = end_time if end_time else None
    min_duration_s_val = float(min_duration_s) if min_duration_s else 0.0

    print(
        f"  å‚æ•°: start_time={start_time}, end_time={end_time}, keywords={keywords_list}, min_duration_s={min_duration_s_val}, limit={limit}")

    # ä¿®å¤è¿™é‡Œï¼šå®‰å…¨åœ°å¤„ç† min_duration_s æ¯”è¾ƒ
    if min_duration_s is not None:
        min_duration_s_val = float(min_duration_s) if min_duration_s else 0.0
    else:
        min_duration_s_val = None

    # åŸæœ‰çš„ç”Ÿæˆå’Œè§£æé€»è¾‘ä¿æŒä¸å˜...
    # 1. ç”Ÿæˆæ—¥å¿—ï¼ˆåŸå§‹å­—ç¬¦ä¸²ï¼‰
    raw_logs = generate_mysql_logs_for_server(server_ip, 60)

    # è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¶é—´å­—ç¬¦ä¸²ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    def parse_time_string(time_str: str) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        if not time_str:
            return None

        try:
            if 'T' in time_str:
                time_str = time_str.replace('T', ' ')
                if '.' in time_str:
                    time_str = time_str.split('.')[0]
        except Exception:
            pass

        try:
            return datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            try:
                return datetime.fromisoformat(time_str)
            except Exception:
                print(f"[è­¦å‘Š] æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
                return None

    # è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¥å¿—æ—¶é—´æˆ³
    def parse_ts(log: str) -> Optional[datetime]:
        try:
            ts_str = log[:19]  # å‡è®¾æ ¼å¼ä¸º "YYYY-MM-DD HH:MM:SS"
            return datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S")
        except Exception:
            return None

    # å…³é”®è¯è¿‡æ»¤
    if keywords_list:
        raw_logs = [log for log in raw_logs if any(k.lower() in log.lower() for k in keywords_list)]

    # æœ€å°è€—æ—¶è¿‡æ»¤ï¼ˆç­›é€‰æ…¢ SQLï¼‰
    if min_duration_s_val and min_duration_s_val > 0:
        filtered = []
        for log in raw_logs:
            import re
            duration_match = re.search(r'duration=([\d.]+)s', log)
            if duration_match:
                duration = float(duration_match.group(1))
                if duration >= min_duration_s_val:
                    filtered.append(log)
        raw_logs = filtered

    # æ—¶é—´çª—è¿‡æ»¤ï¼ˆé™æµï¼‰
    if start_time:
        start_dt = parse_time_string(start_time)
        if start_dt:
            raw_logs = [log for log in raw_logs if parse_ts(log) and parse_ts(log) >= start_dt]

    if end_time:
        end_dt = parse_time_string(end_time)
        if end_dt:
            raw_logs = [log for log in raw_logs if parse_ts(log) and parse_ts(log) <= end_dt]

    # æ’åºï¼Œå°†æ‰€æœ‰æ—¥å¿—æŒ‰ç…§æ—¶é—´æˆ³å‡åºæ’åº
    raw_logs.sort(key=lambda x: parse_ts(x) or datetime.min)
    print(f"[å·¥å…·è°ƒç”¨] æ‰¾åˆ° {len(raw_logs)} æ¡ MySQL æ—¥å¿—")

    # è§£æ â†’ ç»Ÿä¸€ç»“æ„ UnifiedLogV1 â†’ å¹¶åªç­›é€‰limitæ¡æ—¥å¿—
    batch_logs = raw_logs[:limit]
    structured_logs = []
    next_start_time = None

    for log in batch_logs:
        try:
            import re
            # æ—¶é—´æˆ³
            ts = log[:19]
            # ä¸¥é‡çº§åˆ«
            sev_match = re.search(r"\[(INFO|WARN|ERROR)\]", log)
            severity = sev_match.group(1) if sev_match else "INFO"

            # SQL
            sql_match = re.search(r'sql="([^"]+)"', log)
            sql = sql_match.group(1) if sql_match else "UNKNOWN SQL"

            # è€—æ—¶
            dur_match = re.search(r'duration=([\d.]+)s', log)
            latency_ms = float(dur_match.group(1)) * 1000 if dur_match else 0.0

            status = "ERROR" if severity == "ERROR" else "OK"

            structured_logs.append({
                "source": "mysql",
                "server_ip": server_ip,
                "timestamp": ts,
                "severity": severity,
                "operation": sql,
                "status": status,
                "latency_ms": latency_ms,
                "raw": log
            })

            next_start_time = ts

        except Exception as e:
            print(f"[è­¦å‘Š] è§£æ MySQL æ—¥å¿—å¤±è´¥: {e}")
            continue

    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
    if len(batch_logs) < limit:
        next_start_time = None

    return structured_logs, next_start_time


def mysql_runtime_diagnosis_raw(
        server_ip: str,
        action: str,
) -> Dict[str, Any]:
    """
    MySQL è¿è¡Œæ—¶è¯Šæ–­å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰
    """
    print(f"[å·¥å…·è°ƒç”¨] mysql_runtime_diagnosis(server_ip={server_ip}, action={action})")

    if action == "processlist":
        return {
            "type": "processlist",
            "processes": [
                {
                    "id": 1234,
                    "user": "app_user",
                    "db": "order_db",
                    "time_sec": 85,
                    "state": "Waiting for lock",
                    "sql": "UPDATE orders SET status='PAID' WHERE id=10001"
                },
                {
                    "id": 1235,
                    "user": "report_user",
                    "db": "order_db",
                    "time_sec": 2,
                    "state": "Sending data",
                    "sql": "SELECT * FROM orders WHERE created_at > NOW() - INTERVAL 1 DAY"
                }
            ]
        }

    elif action == "innodb_status":
        return {
            "type": "innodb_status",
            "latest_deadlock": {
                "transaction_1": "UPDATE orders SET status='PAID' WHERE id=10001",
                "transaction_2": "UPDATE orders SET status='CANCEL' WHERE id=10001",
                "locked_table": "orders",
                "locked_index": "PRIMARY",
                "note": "ä¸¤ä¸ªäº‹åŠ¡äº’ç›¸ç­‰å¾…è¡Œé”ï¼Œäº§ç”Ÿæ­»é”"
            }
        }
    elif action == "variables":
        return {
            "type": "variables",
            "slow_query_log": "ON",
            "slow_query_log_file": "/var/log/mysql/slow.log",
            "long_query_time": 2,
            "max_connections": 500
        }

    elif action == "connections":
        return {
            "type": "connections",
            "threads_connected": 480,
            "threads_running": 120,
            "max_connections": 500,
            "warning": "è¿æ¥æ•°æ¥è¿‘ä¸Šé™"
        }

    else:
        return {
            "error": f"ä¸æ”¯æŒçš„è¯Šæ–­åŠ¨ä½œ: {action}"
        }


def get_redis_logs_simple_raw(
    server_ip: str,
    keywords: Optional[Union[str, List[str]]] = None,
    min_duration: Optional[float] = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """
    è·å– Redis æ—¥å¿—å¹¶è§£ææˆ UnifiedLogV1 æ ¼å¼
    """
    print(f"[å·¥å…·è°ƒç”¨] get_redis_logs_simple('{server_ip}', keywords={keywords}, min_duration_s={min_duration})")

    logs = generate_redis_logs_for_server(server_ip, 60)

    # å…³é”®è¯è¿‡æ»¤
    if keywords:
        if isinstance(keywords, str):
            keywords = [keywords]
        logs = [log for log in logs if any(k.lower() in log.lower() for k in keywords)]

    # æœ€å°è€—æ—¶è¿‡æ»¤
    if min_duration:
        filtered = []
        for log in logs:
            import re
            dur_match = re.search(r'duration=(\d+)ms', log)
            if dur_match:
                dur_ms = int(dur_match.group(1))
                if dur_ms >= min_duration * 1000:
                    filtered.append(log)
        logs = filtered

    # ç»Ÿä¸€ç»“æ„åŒ–
    structured = []
    import re

    for log in logs[:15]:
        try:
            ts = re.match(r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})", log).group(1)
            severity = re.search(r"\[(INFO|WARN|ERROR|SLOWLOG)\]", log).group(1)

            cmd_match = re.search(r'command="([^"]+)"', log)
            command = cmd_match.group(1) if cmd_match else "UNKNOWN"

            dur_match = re.search(r'duration=(\d+)ms', log)
            latency_ms = int(dur_match.group(1)) if dur_match else 0

            status = "ERROR" if "ERROR" in severity else "OK"

            structured.append({
                "source": "redis",
                "server_ip": server_ip,
                "timestamp": ts,
                "severity": severity,
                "operation": command,
                "status": status,
                "latency_ms": latency_ms,
                "raw": log
            })

        except Exception as e:
            print(f"[è­¦å‘Š] Redis æ—¥å¿—è§£æå¤±è´¥: {e}")
            continue

    return structured


def get_server_metrics_simple_raw(
        server_ip: str,
        metric_name: str = None
) -> Dict[str, Any]:
    """
    ç®€åŒ–çš„æŒ‡æ ‡è·å–å·¥å…·ï¼Œé¿å…å¤æ‚çš„å‚æ•°éªŒè¯é—®é¢˜ã€‚
    """
    print(f"[å·¥å…·è°ƒç”¨] get_server_metrics_simple('{server_ip}', metric_name={metric_name})")

    # ç”Ÿæˆæ¨¡æ‹ŸæŒ‡æ ‡
    all_metrics = generate_metrics_for_server(server_ip, 60)

    # è¿‡æ»¤æŒ‡å®šçš„æŒ‡æ ‡
    if metric_name:
        metric_mapping = {
            "cpu": "cpu_percent",
            "cpu_usage_total": "cpu_percent",
            "å†…å­˜": "memory_percent",
            "memory": "memory_percent",
            "ç£ç›˜": "disk_percent",
            "disk": "disk_percent",
            "æˆåŠŸç‡": "success_rate",
            "é”™è¯¯ç‡": "success_rate",
            "å»¶è¿Ÿ": "avg_latency_ms",
            "å“åº”æ—¶é—´": "avg_latency_ms"
        }

        actual_key = metric_mapping.get(metric_name.lower(), metric_name)
        if actual_key in all_metrics:
            return {actual_key: all_metrics[actual_key]}
        else:
            return {"error": f"æœªæ‰¾åˆ°æŒ‡æ ‡: {metric_name}"}
    else:
        # è¿”å›æ‰€æœ‰æŒ‡æ ‡
        return all_metrics


# ==================== ä½¿ç”¨@toolè£…é¥°çš„ç‰ˆæœ¬ï¼ˆä¾›CrewAIä½¿ç”¨ï¼‰====================
from crewai.tools import tool

@tool("è·å–NginxæœåŠ¡å™¨åˆ—è¡¨")
def get_nginx_servers() -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰NginxæœåŠ¡å™¨çš„IPåœ°å€å’ŒåŸºæœ¬ä¿¡æ¯ã€‚"""
    return get_nginx_servers_raw()


@tool("è·å–æœåŠ¡å™¨æ—¥å¿—")
def get_server_logs_simple(
        server_ip: str,
        api_endpoint: str = None,
        keywords: Union[str, List[str]] = None
) -> List[Dict[str, Any]]:
    """è·å–æœåŠ¡å™¨æ—¥å¿—ï¼ˆNginxï¼‰ï¼Œå¹¶è¾“å‡ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1"""
    return get_server_logs_simple_raw(server_ip, api_endpoint, keywords)


@tool("è·å–MySQLæ—¥å¿—")
def get_mysql_logs_simple(
        server_ip: str,
        start_time: str = "",
        end_time: str = "",
        keywords: str = "",
        min_duration_s: float = 0.0,
        limit: int = 1000
) -> Tuple[List[Dict[str, Any]], Optional[str]]:
    """è·å– MySQL æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿï¼‰ï¼Œå¹¶è§£æä¸ºç»Ÿä¸€æ—¥å¿—ç»“æ„ UnifiedLogV1 æ ¼å¼ã€‚"""
    return get_mysql_logs_simple_raw(server_ip, start_time, end_time, keywords, min_duration_s, limit)


@tool("MYSQLè¿è¡Œæ—¶è¯Šæ–­")
def mysql_runtime_diagnosis(
        server_ip: str,
        action: str,
) -> Dict[str, Any]:
    """MySQL è¿è¡Œæ—¶è¯Šæ–­å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    return mysql_runtime_diagnosis_raw(server_ip, action)


@tool("è·å–Redisæ—¥å¿—")
def get_redis_logs_simple(
    server_ip: str,
    keywords: Optional[Union[str, List[str]]] = None,
    min_duration: Optional[float] = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """è·å– Redis æ—¥å¿—å¹¶è§£ææˆ UnifiedLogV1 æ ¼å¼"""
    return get_redis_logs_simple_raw(server_ip, keywords, min_duration, **kwargs)


@tool("è·å–æœåŠ¡å™¨æŒ‡æ ‡")
def get_server_metrics_simple(
        server_ip: str,
        metric_name: str = None
) -> Dict[str, Any]:
    """ç®€åŒ–çš„æŒ‡æ ‡è·å–å·¥å…·ï¼Œé¿å…å¤æ‚çš„å‚æ•°éªŒè¯é—®é¢˜ã€‚"""
    return get_server_metrics_simple_raw(server_ip, metric_name)


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_tools_locally():
    """æœ¬åœ°æµ‹è¯•å·¥å…·å‡½æ•°"""
    print("ğŸ”§ æœ¬åœ°æµ‹è¯•å·¥å…·å‡½æ•°")

    # æµ‹è¯•æœåŠ¡å™¨åˆ—è¡¨
    servers = get_nginx_servers_raw()
    print(f"è·å–åˆ° {len(servers)} å°æœåŠ¡å™¨")

    # æµ‹è¯•è·å–ç‰¹å®šæœåŠ¡å™¨çš„æ—¥å¿—
    test_server = "10.0.2.101"
    print(f"\næµ‹è¯•æœåŠ¡å™¨ {test_server} çš„æ—¥å¿—:")
    logs = get_server_logs_simple_raw(test_server, api_endpoint="/api/v2/data.json")
    print(f"è·å–åˆ° {len(logs)} æ¡æ—¥å¿—")

    if logs:
        for log in logs[:3]:
            print(f"  - ä¸¥é‡çº§åˆ«: {log['severity']}, æ“ä½œ: {log['operation']}")

    # æµ‹è¯•è·å–æŒ‡æ ‡
    print(f"\næµ‹è¯•æœåŠ¡å™¨ {test_server} çš„æŒ‡æ ‡:")
    metrics = get_server_metrics_simple_raw(test_server, metric_name="cpu")
    print(f"CPUä½¿ç”¨ç‡: {metrics.get('cpu_percent', 'N/A')}%")

    print("\nâœ… æœ¬åœ°æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_tools_locally()
